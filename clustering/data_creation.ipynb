{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import psycopg2\n",
    "\n",
    "##### 1. Bring corridor grid with no CIV duplicates \n",
    "##### 2. Bring avenues with accidents (per day of week per hour)\n",
    "##### 3. Append injured people from accidentes with only injured people (per avenue per day of week per hour)\n",
    "##### 4. Append killed and injured people from accidents with killed people (per avenue per day of week per hour)\n",
    "##### 5. Append other relevant info (per avenue per day of week per hour)\n",
    "\n",
    "##################################################\n",
    "###\n",
    "### 1. Bring corridor grid with no CIV duplicates \n",
    "###\n",
    "##################################################\n",
    "### We bring the Malla Vial\n",
    "malla = gpd.read_file(\"Malla_Vial_Integral_Bogota_r2.geojson\")\n",
    "### We take relevant info from it\n",
    "malla_short = malla[[\"MVICIV\", \"MVINOMBRE\"]].copy()\n",
    "### We rename some columns so that they match with the columns from siniestros\n",
    "malla_short.rename(columns = {\"MVICIV\": \"CIV\"}, inplace = True)\n",
    "### We perform some basic cleaning\n",
    "malla_short_nonan = malla_short[malla_short[\"CIV\"].notna()]\n",
    "### A highway corridor with a given CIV might have multiple records in Malla Vial. We must drop duplicates on CIV (caveat:\n",
    "    ### we keep the first one with whatever info it has on PK_CALZADA) so that we can append MVINOMBRE to accidents\n",
    "malla_short_no_dup = malla_short_nonan.drop_duplicates(\"CIV\")\n",
    "malla_short_clean = malla_short_no_dup[malla_short_no_dup[\"MVINOMBRE\"].notna()].copy()\n",
    "\n",
    "##### We delete intermediate info\n",
    "del malla\n",
    "del malla_short\n",
    "del malla_short_nonan\n",
    "del malla_short_no_dup\n",
    "\n",
    "##################################################\n",
    "###\n",
    "### 2. Bring corridors with accidents (per day of week per hour)\n",
    "###\n",
    "##################################################\n",
    "db_conn = psycopg2.connect(\n",
    "   database = \"accidents_smb\", user = \"dev\", password = \"dev\", host = \"127.0.0.1\", port = \"5432\"\n",
    ")\n",
    "\n",
    "##### The methodology works by bringing 3-year data. Before running the script, the person who runs it can modify the date\n",
    "    ##### information below (year, month and day) and the script would automatically bring the 3-year data up to such date\n",
    "year = 2021\n",
    "month = 12 # If the month is January, the value should be 1, not 01, and so on\n",
    "day = 31 # If the day is the first day of the month, the value should be 1, not 01, and so on\n",
    "\n",
    "if len(str(month)) == 1:\n",
    "    month = str(0) + str(month)\n",
    "else:\n",
    "    month = str(month)\n",
    "if len(str(day)) == 1:\n",
    "    day = str(0) + str(day)\n",
    "else:\n",
    "    day = str(day)\n",
    "\n",
    "fecha = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
    "fecha2 = str(pd.to_datetime(fecha) - pd.DateOffset(years = 3))[0:10]\n",
    "\n",
    "##### We bring info on accidents\n",
    "query = \"\"\"\n",
    "SELECT FORMULARIO, CIV, DIA_OCURRENCIA_ACC, HORA_OCURRENCIA_ACC\n",
    "FROM siniestros\n",
    "WHERE substring(FECHA_ACC, 1, 10) > '\"\"\" + fecha2 + \"\"\"' AND\n",
    "    substring(FECHA_ACC, 1, 10) <= '\"\"\" + fecha + \"\"\"'\n",
    "\"\"\"\n",
    "accidentes = pd.read_sql(query, con = db_conn)\n",
    "accidentes.columns = accidentes.columns.str.upper()\n",
    "##### We remove corridors with useless CIV (corridor) info\n",
    "accidentes[\"CIV\"].replace({0: np.nan}, inplace = True)\n",
    "accidentes_nonan = accidentes[accidentes[\"CIV\"].notna()].copy()\n",
    "##### We groupby() accidents info to count the number of accidents\n",
    "cant_accidentes = accidentes_nonan.groupby([\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"]).size().\\\n",
    "    reset_index(name = \"accidentes\")\n",
    "\n",
    "##################################################\n",
    "###\n",
    "### 3. Append injured people from accidentes with only injured people (per corridor per day of week per hour)\n",
    "###\n",
    "##################################################\n",
    "##### We bring info on accidents with injured people (but not deaths)\n",
    "query = \"\"\"\n",
    "SELECT siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC,\n",
    "    COUNT(conheridos.FORMULARIO) AS heridos\n",
    "FROM siniestros\n",
    "JOIN conheridos ON conheridos.FORMULARIO = siniestros.FORMULARIO\n",
    "WHERE substring(siniestros.FECHA_ACC, 1, 10) > '\"\"\" + fecha2 + \"\"\"' AND\n",
    "    substring(siniestros.FECHA_ACC, 1, 10) <= '\"\"\" + fecha + \"\"\"' AND\n",
    "    siniestros.GRAVEDAD = 'CON HERIDOS'\n",
    "GROUP BY siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC\n",
    "ORDER BY heridos DESC\n",
    "\"\"\"\n",
    "heridos = pd.read_sql(query, con = db_conn)\n",
    "heridos.columns = heridos.columns.str.upper()\n",
    "heridos.rename({\"HERIDOS\": \"heridos\"}, axis = 1, inplace = True)\n",
    "##### We remove corridors with useless CIV (corridor) info\n",
    "heridos[\"CIV\"].replace({0: np.nan}, inplace = True)\n",
    "heridos_nonan = heridos[heridos[\"CIV\"].notna()].copy()\n",
    "##### We groupby() injured people info to sum the number of injured people\n",
    "cant_heridos = heridos_nonan.groupby([\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"])[\"heridos\"].sum().\\\n",
    "    reset_index(name = \"heridos\")\n",
    "\n",
    "##################################################\n",
    "###\n",
    "### 4. Append killed and injured people from accidents with killed people (per corridor per day of week per hour)\n",
    "###\n",
    "##################################################\n",
    "##### We bring info on accidents with killed people and append to them the number of injured people\n",
    "query = \"\"\"\n",
    "WITH fallecidos AS (\n",
    "    SELECT siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC,\n",
    "        COUNT(confallecidos.FORMULARIO) AS muertes\n",
    "    FROM siniestros\n",
    "    JOIN confallecidos on confallecidos.FORMULARIO = siniestros.FORMULARIO\n",
    "    WHERE substring(siniestros.FECHA_ACC, 1, 10) > '\"\"\" + fecha2 + \"\"\"' AND\n",
    "        substring(siniestros.FECHA_ACC, 1, 10) <= '\"\"\" + fecha + \"\"\"'\n",
    "    GROUP BY siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC\n",
    ")\n",
    "SELECT fallecidos.FORMULARIO, fallecidos.CIV, fallecidos.DIA_OCURRENCIA_ACC, fallecidos.HORA_OCURRENCIA_ACC,\n",
    "    fallecidos.muertes, COUNT(conheridos.FORMULARIO) AS heridos\n",
    "FROM fallecidos\n",
    "LEFT JOIN conheridos ON conheridos.FORMULARIO = fallecidos.FORMULARIO\n",
    "GROUP BY fallecidos.FORMULARIO, fallecidos.CIV, fallecidos.DIA_OCURRENCIA_ACC, fallecidos.HORA_OCURRENCIA_ACC,\n",
    "    fallecidos.muertes\n",
    "ORDER BY fallecidos.muertes DESC, heridos DESC\n",
    "\"\"\"\n",
    "muertes = pd.read_sql(query, con = db_conn)\n",
    "muertes.columns = muertes.columns.str.upper()\n",
    "muertes.rename({\"MUERTES\": \"muertes\", \"HERIDOS\": \"heridos\"}, axis = 1, inplace = True)\n",
    "##### We remove corridors with useless CIV (corridor) info\n",
    "muertes[\"CIV\"].replace({0: np.nan}, inplace = True)\n",
    "muertes_nonan = muertes[muertes[\"CIV\"].notna()].copy()\n",
    "##### We groupby() killed and injured people info to sum the number of killed and injured people\n",
    "cant_muertes = muertes_nonan.groupby([\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"])[[\"muertes\", \"heridos\"]].sum().\\\n",
    "    reset_index()\n",
    "\n",
    "##################################################\n",
    "###\n",
    "### 5. Append other relevant info (per corridor per day of week per hour)\n",
    "###\n",
    "##################################################\n",
    "##################################################\n",
    "### Append injured vulnerable people from accidentes with only injured vulnerable people (per corridor per day of week per\n",
    "### hour)\n",
    "##################################################\n",
    "##### We bring the number of vulnerable road actors injured in accidents\n",
    "query = \"\"\"\n",
    "SELECT siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC, \n",
    "    COUNT(conheridos.FORMULARIO) FILTER (WHERE conheridos.CONDICION IN ('PEATON', 'CICLISTA', 'MOTOCICLISTA'))\n",
    "        AS heridos_vulnerables \n",
    "FROM siniestros\n",
    "JOIN conheridos ON conheridos.FORMULARIO = siniestros.FORMULARIO\n",
    "WHERE substring(siniestros.FECHA_ACC, 1, 10) > '\"\"\" + fecha2 + \"\"\"' AND\n",
    "    substring(siniestros.FECHA_ACC, 1, 10) <= '\"\"\" + fecha + \"\"\"' AND\n",
    "    siniestros.GRAVEDAD = 'CON HERIDOS'\n",
    "GROUP BY siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC\n",
    "ORDER BY heridos_vulnerables DESC\n",
    "\"\"\"\n",
    "heridosv = pd.read_sql(query, con = db_conn)\n",
    "heridosv.columns = heridosv.columns.str.upper()\n",
    "heridosv.rename({\"HERIDOS_VULNERABLES\": \"heridos_vulnerables\"}, axis = 1, inplace = True)\n",
    "##### We remove corridors with useless CIV (corridor) info\n",
    "heridosv[\"CIV\"].replace({0: np.nan}, inplace = True)\n",
    "heridosv_nonan = heridosv[heridosv[\"CIV\"].notna()].copy()\n",
    "##### We groupby() injured vulnerable people info to sum the number of injured vulnerable people\n",
    "cant_heridosv = heridosv_nonan.groupby([\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"])[\"heridos_vulnerables\"].sum().\\\n",
    "    reset_index()\n",
    "\n",
    "##################################################\n",
    "### Append killed and injured vulnerable people from accidentes with killed vulnerable people (per corridor per day of week\n",
    "### per hour)\n",
    "##################################################\n",
    "##### We bring the number of vulnerable road actors killed and injured in accidents with killed vulnerable people\n",
    "query = \"\"\"\n",
    "WITH fallecidos AS (\n",
    "    SELECT siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC, \n",
    "        COUNT(confallecidos.FORMULARIO) FILTER (WHERE confallecidos.CONDICION IN ('PEATON', 'CICLISTA', 'MOTOCICLISTA'))\n",
    "            AS muertes_vulnerables \n",
    "    FROM siniestros\n",
    "    JOIN confallecidos ON confallecidos.FORMULARIO = siniestros.FORMULARIO\n",
    "    WHERE substring(siniestros.FECHA_ACC, 1, 10) > '\"\"\" + fecha2 + \"\"\"' AND\n",
    "        substring(siniestros.FECHA_ACC, 1, 10) <= '\"\"\" + fecha + \"\"\"'\n",
    "    GROUP BY siniestros.FORMULARIO, siniestros.CIV, siniestros.DIA_OCURRENCIA_ACC, siniestros.HORA_OCURRENCIA_ACC\n",
    ")\n",
    "SELECT fallecidos.FORMULARIO, fallecidos.CIV, fallecidos.DIA_OCURRENCIA_ACC, fallecidos.HORA_OCURRENCIA_ACC,\n",
    "    fallecidos.muertes_vulnerables,\n",
    "    COUNT(conheridos.FORMULARIO) FILTER (WHERE conheridos.CONDICION IN ('PEATON', 'CICLISTA', 'MOTOCICLISTA'))\n",
    "        AS heridos_vulnerables\n",
    "FROM fallecidos\n",
    "LEFT JOIN conheridos ON conheridos.FORMULARIO = fallecidos.FORMULARIO\n",
    "GROUP BY fallecidos.FORMULARIO, fallecidos.CIV, fallecidos.DIA_OCURRENCIA_ACC, fallecidos.HORA_OCURRENCIA_ACC,\n",
    "    fallecidos.muertes_vulnerables\n",
    "ORDER BY fallecidos.muertes_vulnerables DESC, heridos_vulnerables DESC\n",
    "\"\"\"\n",
    "muertesv = pd.read_sql(query, con = db_conn)\n",
    "db_conn.close()\n",
    "muertesv.columns = muertesv.columns.str.upper()\n",
    "muertesv.rename({\"MUERTES_VULNERABLES\": \"muertes_vulnerables\", \"HERIDOS_VULNERABLES\": \"heridos_vulnerables\"}, axis = 1, \\\n",
    "    inplace = True)\n",
    "##### We remove corridors with useless CIV (corridor) info\n",
    "muertesv[\"CIV\"].replace({0: np.nan}, inplace = True)\n",
    "muertesv_nonan = muertesv[muertesv[\"CIV\"].notna()].copy()\n",
    "##### We groupby() killed vulnerable people info to sum the number of killed vulnerable people\n",
    "cant_muertesv = muertesv_nonan.groupby([\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"])[[\"muertes_vulnerables\", \\\n",
    "    \"heridos_vulnerables\"]].sum().reset_index()\n",
    "\n",
    "##### We bring everything together, including the corridor names\n",
    "accidentes_malla = pd.merge(cant_accidentes, cant_heridos, how = \"left\", on = [\"CIV\", \"DIA_OCURRENCIA_ACC\", \\\n",
    "    \"HORA_OCURRENCIA_ACC\"]).merge(cant_muertes, how = \"left\", on = [\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"]).\\\n",
    "    merge(cant_heridosv, how = \"left\", on = [\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"]).\\\n",
    "    merge(cant_muertesv, how = \"left\", on = [\"CIV\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"]).\\\n",
    "    merge(malla_short_clean, how = \"left\", on = \"CIV\")\n",
    "##### We remove corridors with no name\n",
    "accidentes_malla_clean = accidentes_malla[accidentes_malla[\"MVINOMBRE\"].notna()].copy()\n",
    "##### We fill features with 0s when applicable \n",
    "accidentes_malla_clean.fillna(value = 0, inplace = True)\n",
    "##### We adjust some features \n",
    "accidentes_malla_clean[\"heridos\"] = accidentes_malla_clean[\"heridos_x\"] + accidentes_malla_clean[\"heridos_y\"]\n",
    "accidentes_malla_clean[\"heridos_vulnerables\"] = accidentes_malla_clean[\"heridos_vulnerables_x\"] + \\\n",
    "    accidentes_malla_clean[\"heridos_vulnerables_y\"]\n",
    "accidentes_malla_clean.drop(columns = [\"heridos_x\", \"heridos_y\", \"heridos_vulnerables_x\", \"heridos_vulnerables_y\"], \\\n",
    "    axis = 1, inplace = True)\n",
    "accidentes_malla_clean[\"muertes\"] = accidentes_malla_clean[\"muertes\"].astype(int)\n",
    "accidentes_malla_clean[\"heridos\"] = accidentes_malla_clean[\"heridos\"].astype(int)\n",
    "accidentes_malla_clean[\"muertes_vulnerables\"] = accidentes_malla_clean[\"muertes_vulnerables\"].astype(int)\n",
    "accidentes_malla_clean[\"heridos_vulnerables\"] = accidentes_malla_clean[\"heridos_vulnerables\"].astype(int)\n",
    "\n",
    "##### We groupby() to sum all the relevant features\n",
    "info_siniestros = accidentes_malla_clean.groupby([\"MVINOMBRE\", \"DIA_OCURRENCIA_ACC\", \"HORA_OCURRENCIA_ACC\"])\\\n",
    "    [[\"accidentes\", \"muertes\", \"heridos\", \"muertes_vulnerables\", \"heridos_vulnerables\"]].sum().reset_index()\n",
    "\n",
    "##### We delete intermediate info\n",
    "del accidentes\n",
    "del accidentes_malla\n",
    "del accidentes_malla_clean\n",
    "del heridos\n",
    "del heridos_nonan\n",
    "del heridosv\n",
    "del heridosv_nonan\n",
    "del muertes\n",
    "del muertes_nonan\n",
    "del muertesv\n",
    "del muertesv_nonan\n",
    "del cant_accidentes\n",
    "del cant_heridos\n",
    "del cant_heridosv\n",
    "del cant_muertes\n",
    "del cant_muertesv\n",
    "\n",
    "##### We create the hour blocks (Lissett's version)\n",
    "d1 = {\n",
    "    0: \"Nocturno 22-2\",\n",
    "    1: \"Nocturno 22-2\",\n",
    "    2: \"Nocturno 2-5\",\n",
    "    3: \"Nocturno 2-5\",\n",
    "    4: \"Nocturno 2-5\",\n",
    "    5: \"DiurnoMan 5-8\",\n",
    "    6: \"DiurnoMan 5-8\",\n",
    "    7: \"DiurnoMan 5-8\",\n",
    "    8: \"DiurnoMan 8-12\",\n",
    "    9: \"DiurnoMan 8-12\",\n",
    "    10: \"DiurnoMan 8-12\",\n",
    "    11: \"DiurnoMan 8-12\",\n",
    "    12: \"DiurnoTarde 12-18\",\n",
    "    13: \"DiurnoTarde 12-18\",\n",
    "    14: \"DiurnoTarde 12-18\",\n",
    "    15: \"DiurnoTarde 12-18\",\n",
    "    16: \"DiurnoTarde 12-18\",\n",
    "    17: \"DiurnoTarde 12-18\",\n",
    "    18: \"NocturnoTarde 18-22\",\n",
    "    19: \"NocturnoTarde 18-22\",\n",
    "    20: \"NocturnoTarde 18-22\",\n",
    "    21: \"NocturnoTarde 18-22\",\n",
    "    22: \"Nocturno 22-2\",\n",
    "    23: \"Nocturno 22-2\",\n",
    "}\n",
    "info_siniestros[\"HORARIO\"] = info_siniestros[\"HORA_OCURRENCIA_ACC\"].map(d1)\n",
    "\n",
    "##### We keep corridors with deaths \n",
    "# Create list with corridors that had 0 deaths\n",
    "lstm = info_siniestros.groupby(\"MVINOMBRE\")[\"muertes\"].sum()[info_siniestros.groupby(\"MVINOMBRE\")[\"muertes\"].sum() == 0].\\\n",
    "    index.to_list()\n",
    "# Create df without such corridors\n",
    "info_siniestrosm = info_siniestros[~info_siniestros[\"MVINOMBRE\"].isin(lstm)]\n",
    "\n",
    "##### We groupby() using the corridors, days and time blocks\n",
    "info_siniestrosmh = info_siniestrosm.groupby([\"MVINOMBRE\", \"DIA_OCURRENCIA_ACC\", \"HORARIO\"])[[\"accidentes\", \"muertes\", \\\n",
    "    \"heridos\", \"muertes_vulnerables\", \"heridos_vulnerables\"]].sum().reset_index()\n",
    "\n",
    "##################################################\n",
    "###\n",
    "### Final preparation\n",
    "###\n",
    "##################################################\n",
    "##### We create the data for the clustering prediction\n",
    "cluster_df = info_siniestrosmh.copy()\n",
    "\n",
    "##### Day of week seems somewhat irrelevant according to a basic EDA not reported here. We get rid of it\n",
    "# We groupby() using the corridors and time blocks\n",
    "cluster_df = cluster_df.groupby([\"MVINOMBRE\", \"HORARIO\"])[[\"accidentes\", \"muertes\", \"heridos\", \"muertes_vulnerables\", \\\n",
    "    \"heridos_vulnerables\"]].sum().reset_index()\n",
    "\n",
    "def vulnerable(muertesv, heridosv):\n",
    "    \"\"\"\n",
    "    This function creates an indicator of the degree of severity of accidentes in a corridor.\n",
    "\n",
    "    Args:\n",
    "        muertesv: the number of vulnerable killed people.\n",
    "        heridosv: the number of vulnerable injured people. \n",
    "\n",
    "    Returns:\n",
    "        The degree of severity.\n",
    "            0: neither killed nor injured vulnerable people\n",
    "            1: injured vulnerable people but no killed vulnerable people\n",
    "            2: killed vulnerable people\n",
    "    \"\"\"\n",
    "    \n",
    "    if muertesv == 0 and heridosv == 0:\n",
    "        return 0 \n",
    "    elif heridosv > 0 and muertesv == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "cluster_df[\"vulnerables\"] = cluster_df.apply(lambda x: vulnerable(x[\"muertes_vulnerables\"], x[\"heridos_vulnerables\"]), \\\n",
    "    axis = 1)\n",
    "cluster_df[\"vulnerables\"] = cluster_df[\"vulnerables\"].astype(\"category\")\n",
    "\n",
    "##### We can save the data to use it later with the saved scaler and the saved model to make prioritization predictions\n",
    "#cluster_df.to_csv(\"raw_data_predict.csv\", index = False)\n",
    "\n",
    "del info_siniestros\n",
    "del info_siniestrosm\n",
    "del info_siniestrosmh\n",
    "del cluster_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14a8ab31f43739f8c61e31f0a764b4b9450b359fd4dd373e840d3db42f338d08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
