{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accidents\n",
    "\n",
    "df_list = [] # List to store DataFrames generated from JSON files\n",
    "\n",
    "# Retrieve list of JSON files\n",
    "json_pattern = os.path.join(\"./shapefiles/accidents\",'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "i = 0 # We create this auxiliary variable to keep track of the process\n",
    "for file in file_list:\n",
    "    # Read a JSON file\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    # Load the JSON file into a DataFrame and store the DataFrame in a list of DataFrames\n",
    "        # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8. Check Section 3\n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "    i += 1\n",
    "    print(\"Iter \" + str(i))\n",
    "\n",
    "# Concatenate all DataFrames from the list into a single DataFrame\n",
    "accidents_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {} # Dictionary to store old and new column names for the concatenated DataFrame\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "for i in range(len(accidents_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({accidents_df.columns[i]: accidents_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "accidents_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "# There're repeated indexes, which can cause problems when saving the data in a JSON.\n",
    "# We take care of this by resetting the index and dropping the generated index column\n",
    "accidents_df.reset_index(inplace = True)\n",
    "accidents_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "# We save the merged data in a JSON file\n",
    "accidents_df.to_json(\"shapefiles/accidents/accidents_2015-2022.json\")\n",
    "\n",
    "# accidents_df = pd.read_json(\"shapefiles/accidents/accidents_2015-2022.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injured people\n",
    "\n",
    "df_list = [] # List to store DataFrames generated from JSON files\n",
    "\n",
    "# Retrieve list of JSON files\n",
    "json_pattern = os.path.join(\"./shapefiles/injured\",'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "i = 0 # We create this auxiliary variable to keep track of the process\n",
    "for file in file_list:\n",
    "    # Read a JSON file\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    # Load the JSON file into a DataFrame and store the DataFrame in a list of DataFrames\n",
    "        # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8. Check Section 3\n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "    i += 1\n",
    "    print(\"Iter \" + str(i))\n",
    "\n",
    "# Concatenate all DataFrames from the list into a single DataFrame\n",
    "injured_people_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {} # Dictionary to store old and new column names for the concatenated DataFrame\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "for i in range(len(injured_people_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({injured_people_df.columns[i]: injured_people_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "injured_people_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "# There're repeated indexes, which can cause problems when saving the data in a JSON.\n",
    "# We take care of this by resetting the index and dropping the generated index column\n",
    "injured_people_df.reset_index(inplace = True)\n",
    "injured_people_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "# We save the merged data in a JSON file\n",
    "injured_people_df.to_json(\"shapefiles/injured/injured_people_2015-2022.json\")\n",
    "\n",
    "# injured_people_df = pd.read_json(\"shapefiles/injured_people/injured_people_2015-2022.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Killed people\n",
    "\n",
    "# We make sure to remove unnecessary data from killed people.\n",
    "# We're working with data from 2015 up to Aug 2022. When bringing data from killed people, we brought it from 2015 up to the\n",
    "# current day.\n",
    "# We need to remove data from Sep 2022\n",
    "\n",
    "# We load data from killed people\n",
    "with open('shapefiles/killed/killed_people_2015-2022.json','r') as f:\n",
    "    data = json.loads(f.read())\n",
    "killed_people_df = pd.json_normalize(data, record_path = [\"features\"])\n",
    "\n",
    "column_dict = {} # Dictionary to store old and new column names for the DataFrame\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "for i in range(len(killed_people_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({killed_people_df.columns[i]: killed_people_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "killed_people_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "# We bring the accident codes to a list\n",
    "# accidents_df = pd.read_json(\"shapefiles/accidents/accidents_2015-2022.json\")\n",
    "accident_code_list = accidents_df[\"FORMULARIO\"].to_list()\n",
    "\n",
    "# We filter killed people by accident codes \n",
    "killed_people_df_r = killed_people_df[killed_people_df[\"FORMULARIO\"].isin(accident_code_list)].copy()\n",
    "\n",
    "# We save the DataFrame in a JSON file\n",
    "killed_people_df_r.to_json(\"shapefiles/killed/killed_people_2015-2022_r1.json\")\n",
    "\n",
    "# killed_people_df = pd.read_json(\"shapefiles/killed/killed_people_2015-2022_r1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicles\n",
    "\n",
    "df_list = []\n",
    "\n",
    "json_pattern = os.path.join(\"./shapefiles/vehicles\",'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "i = 0\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "    i += 1\n",
    "    print(\"Iter \" + str(i))\n",
    "\n",
    "vehicles_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {}\n",
    "\n",
    "for i in range(len(vehicles_df.columns)):\n",
    "    column_dict.update({vehicles_df.columns[i]: vehicles_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "vehicles_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "vehicles_df.reset_index(inplace = True)\n",
    "vehicles_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "# We make sure to remove unnecessary data from vehicles.\n",
    "# We're working with data from 2015 up to Aug 2022. When bringing data from vehicles, we brought it all up to the current day\n",
    "\n",
    "# We filter vehicles by accident codes \n",
    "# accidents_df = pd.read_json(\"shapefiles/accidents/accidents_2015-2022.json\")\n",
    "vehicles_df_r = vehicles_df[vehicles_df[\"FORMULARIO\"].isin(accident_code_list)].copy()\n",
    "\n",
    "# We save the merged data in a JSON file\n",
    "vehicles_df_r.to_json(\"shapefiles/vehicles/vehicles_2015-2022.json\")\n",
    "\n",
    "# vehicles_df = pd.read_json(\"shapefiles/vehicles/vehicles_2015-2022.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causes\n",
    "\n",
    "df_list = []\n",
    "\n",
    "json_pattern = os.path.join(\"./shapefiles/causes\",'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "i = 0\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "    i += 1\n",
    "    print(\"Iter \" + str(i))\n",
    "\n",
    "causes_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {}\n",
    "\n",
    "for i in range(len(causes_df.columns)):\n",
    "    column_dict.update({causes_df.columns[i]: causes_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "causes_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "causes_df.reset_index(inplace = True)\n",
    "causes_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "# We make sure to remove unnecessary data from causes.\n",
    "# We're working with data from 2015 up to Aug 2022. When bringing data from causes, we brought it all up to the current day\n",
    "\n",
    "# We filter causes by accident codes \n",
    "# accidents_df = pd.read_json(\"shapefiles/accidents/accidents_2015-2022.json\")\n",
    "causes_df_r = causes_df[causes_df[\"FORMULARIO\"].isin(accident_code_list)].copy()\n",
    "\n",
    "# We save the merged data in a JSON file\n",
    "causes_df_r.to_json(\"shapefiles/causes/causes_2015-2022.json\")\n",
    "\n",
    "# causes_df = pd.read_json(\"shapefiles/causes/causes_2015-2022.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Actors\n",
    "\n",
    "df_list = []\n",
    "\n",
    "json_pattern = os.path.join(\"./shapefiles/actors\",'*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "i = 0\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "    i += 1\n",
    "    print(\"Iter \" + str(i))\n",
    "\n",
    "actors_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {}\n",
    "\n",
    "for i in range(len(actors_df.columns)):\n",
    "    column_dict.update({actors_df.columns[i]: actors_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "actors_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "actors_df.reset_index(inplace = True)\n",
    "actors_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "# We make sure to remove unnecessary data from actors.\n",
    "# We're working with data from 2015 up to Aug 2022. When bringing data from actors, we brought it all up to the current day\n",
    "\n",
    "# We filter actors by accident codes \n",
    "# accidents_df = pd.read_json(\"shapefiles/accidents/accidents_2015-2022.json\")\n",
    "actors_df_r = actors_df[actors_df[\"FORMULARIO\"].isin(accident_code_list)].copy()\n",
    "\n",
    "# We save the merged data in a JSON file\n",
    "actors_df_r.to_json(\"shapefiles/actors/actors_2015-2022.json\")\n",
    "\n",
    "# actors_df = pd.read_json(\"shapefiles/actors/actors_2015-2022.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
