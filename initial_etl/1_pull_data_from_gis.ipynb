{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### Accidents #####\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015-2021\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/0/query?\"\n",
    "\n",
    "# We create the array with the years we're gonna loop through\n",
    "year_iter = np.arange(2015, 2022)\n",
    "file_name_init = \"shapefiles/accidents/accidents_\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file containing data for each year in the array\n",
    "for year in year_iter:\n",
    "    # The queries are heavy and the GIS service constrains the number of rows that can be retrieved (50,000 rows).\n",
    "    # For this reason, we run queries for each year individually\n",
    "    where_clause = \"ANO_OCURRENCIA_ACC = \" + str(year)\n",
    "    accidents = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CIV, PK_CALZADA, CLASE_ACC, GRAVEDAD, FECHA_HORA_ACC',\n",
    "        'returnGeometry': 'true',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_accidents = urllib.parse.urlencode(accidents).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_accidents = urllib.request.urlopen(url, encode_accidents)\n",
    "    query_accidents = response_accidents.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(year) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_accidents)\n",
    "    print(\"Iter: \" + str(year)) # Keep track of the process (we know how many files we're creating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022 up to Aug\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/0/query?\"\n",
    "\n",
    "accidents = {'where': \"ANO_OCURRENCIA_ACC = 2022 AND MES_OCURRENCIA_ACC IN ('ENERO', 'FEBRERO', 'MARZO', 'ABRIL', 'MAYO', 'JUNIO', 'JULIO', 'AGOSTO')\",\n",
    "    'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CIV, PK_CALZADA, CLASE_ACC, GRAVEDAD, FECHA_HORA_ACC',\n",
    "    'returnGeometry': 'true',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_accidents = urllib.parse.urlencode(accidents).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_accidents = urllib.request.urlopen(url, encode_accidents)\n",
    "query_accidents = response_accidents.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"shapefiles/accidents/accidents_2022.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_accidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### Injured people #####\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2015-2021\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/2/query?\"\n",
    "\n",
    "# We create the array with the years we're gonna loop through\n",
    "year_iter = np.arange(2015, 2022)\n",
    "file_name_init = \"shapefiles/injured/injured_people_\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file containing data for each year in the array\n",
    "for year in year_iter:\n",
    "    # The queries are heavy and the GIS service constrains the number of rows that can be retrieved (50,000 rows).\n",
    "    # For this reason, we run queries for each year individually\n",
    "    where_clause = \"ANO_OCURRENCIA_ACC = \" + str(year)\n",
    "    injured_people = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CLASE_ACC, CONDICION, GENERO, EDAD, FECHA_HORA_ACC',\n",
    "        'returnGeometry': 'true',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_injured_people = urllib.parse.urlencode(injured_people).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_injured_people = urllib.request.urlopen(url, encode_injured_people)\n",
    "    query_injured_people = response_injured_people.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(year) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_injured_people)\n",
    "    print(\"Iter: \" + str(year)) # Keep track of the process (we know how many files we're creating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022 up to Aug\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/2/query?\"\n",
    "\n",
    "injured_people = {'where': \"ANO_OCURRENCIA_ACC = 2022 AND MES_OCURRENCIA_ACC IN ('ENERO', 'FEBRERO', 'MARZO', 'ABRIL', 'MAYO', 'JUNIO', 'JULIO', 'AGOSTO')\",\n",
    "    'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CLASE_ACC, CONDICION, GENERO, EDAD, FECHA_HORA_ACC',\n",
    "    'returnGeometry': 'true',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_injured_people = urllib.parse.urlencode(injured_people).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_injured_people = urllib.request.urlopen(url, encode_injured_people)\n",
    "query_injured_people = response_injured_people.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"shapefiles/injured/injured_people_2022.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_injured_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### Killed people #####\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/1/query?\"\n",
    "\n",
    "# We specify the query\n",
    "killed_people = {'where': 'ANO_OCURRENCIA_ACC >= 2015',\n",
    "    'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CLASE_ACC, CONDICION, GENERO, EDAD, MUERTE_POSTERIOR, FECHA_POSTERIOR_MUERTE, FECHA_HORA_ACC',\n",
    "    'returnGeometry': 'true',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_killed_people = urllib.parse.urlencode(killed_people).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_killed_people = urllib.request.urlopen(url, encode_killed_people)\n",
    "query_killed_people = response_killed_people.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"shapefiles/killed/killed_people_2015-2022.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_killed_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### Causes #####\n",
    "##################################################\n",
    "\n",
    "# For this and the following tables, since there is no date information available, we bring the info using the OBJECTID feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/5/query?\"\n",
    "\n",
    "# Bringing 50,000 rows sometimes causes the server to not respond. So, we decrease the number of rows we bring to minimize the\n",
    "# chances of the server not responding\n",
    "row_constraint = 30000\n",
    "max_objectid = 658183 # Checking on Sep 13, 2022. Max(OBJECTID) matches the number of rows\n",
    "objectid_iter = int(max_objectid / row_constraint)\n",
    "file_name_init = \"shapefiles/causes/causes\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file containing \"row_constraint\" rows each\n",
    "for i in range(objectid_iter):\n",
    "    # We specify the query\n",
    "    lower_objectid = i * row_constraint + 1\n",
    "    upper_objectid = (i + 1) * row_constraint\n",
    "    where_clause = \"OBJECTID BETWEEN \" + str(lower_objectid) + \" AND \" + str(upper_objectid)\n",
    "    causes = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, CODIGO_VEHICULO, CODIGO_CAUSA, NOMBRE, TIPO, TIPO_CAUSA',\n",
    "        'returnGeometry': 'false',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_causes = urllib.parse.urlencode(causes).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_causes = urllib.request.urlopen(url, encode_causes)\n",
    "    query_causes = response_causes.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(i + 1) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_causes)\n",
    "    print(\"Iter: \" + str(i)) # Keep track of the process (we know how many files we're creating)\n",
    "    \n",
    "# We create the last JSON file\n",
    "where_clause = \"OBJECTID > \" + str(upper_objectid)\n",
    "causes = {'where': where_clause,\n",
    "    'outFields': 'OBJECTID, FORMULARIO, CODIGO_VEHICULO, CODIGO_CAUSA, NOMBRE, TIPO, TIPO_CAUSA',\n",
    "    'returnGeometry': 'false',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_causes = urllib.parse.urlencode(causes).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_causes = urllib.request.urlopen(url, encode_causes)\n",
    "query_causes = response_causes.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "file_name = file_name_init + str(objectid_iter + 1) + file_name_end\n",
    "with open(file_name, \"wb\") as json_file:\n",
    "    json_file.write(query_causes)\n",
    "print(\"Last iter\") # Keep track of the process (we know how many files we're creating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### Road actors #####\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/6/query?\"\n",
    "\n",
    "# Bringing 50,000 rows sometimes causes the server to not respond. So, we decrease the number of rows we bring to minimize the\n",
    "# chances of the server not responding\n",
    "row_constraint = 30000\n",
    "max_objectid = 1627505 # Checking on Sep 13, 2022. Max(OBJECTID) matches the number of rows\n",
    "objectid_iter = int(max_objectid / row_constraint)\n",
    "file_name_init = \"shapefiles/actors/actors\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file containing \"row_constraint\" rows each\n",
    "for i in range(objectid_iter):\n",
    "    # We specify the query\n",
    "    lower_objectid = i * row_constraint + 1\n",
    "    upper_objectid = (i + 1) * row_constraint\n",
    "    where_clause = \"OBJECTID BETWEEN \" + str(lower_objectid) + \" AND \" + str(upper_objectid)\n",
    "    actors = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, CODIGO_VICTIMA, CODIGO_VEHICULO, CONDICION, GENERO, EDAD, ESTADO, MUERTE_POSTERIOR, FECHA_POSTERIOR_MUERTE',\n",
    "        'returnGeometry': 'false',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_actors = urllib.parse.urlencode(actors).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_actors = urllib.request.urlopen(url, encode_actors)\n",
    "    query_actors = response_actors.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(i + 1) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_actors)\n",
    "    print(\"Iter: \" + str(i)) # Keep track of the process (we know how many files we're creating)\n",
    "    \n",
    "# We create the last JSON file\n",
    "where_clause = \"OBJECTID > \" + str(upper_objectid)\n",
    "actors = {'where': where_clause,\n",
    "    'outFields': 'OBJECTID, FORMULARIO, CODIGO_VICTIMA, CODIGO_VEHICULO, CONDICION, GENERO, EDAD, ESTADO, MUERTE_POSTERIOR, FECHA_POSTERIOR_MUERTE',\n",
    "    'returnGeometry': 'false',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_actors = urllib.parse.urlencode(actors).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_actors = urllib.request.urlopen(url, encode_actors)\n",
    "query_actors = response_actors.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "file_name = file_name_init + str(objectid_iter + 1) + file_name_end\n",
    "with open(file_name, \"wb\") as json_file:\n",
    "    json_file.write(query_actors)\n",
    "print(\"Last iter\") # Keep track of the process (we know how many files we're creating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "##### Vehicles #####\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/4/query?\"\n",
    "\n",
    "# Unlike OBJECTID in causes and actors, max(OBJECTID) in vehicles doesn't match its number of rows. For this reason, we need to\n",
    "# carefully check OBJECTID to retrieve the info. This is done by manually changing the where clause\n",
    "vehicles = {'where': 'OBJECTID BETWEEN 14262001 AND 15000000',\n",
    "    'outFields': 'OBJECTID, FORMULARIO, CODIGO_VEHICULO, CLASE, SERVICIO, MODALIDAD, ENFUGA',\n",
    "    'returnGeometry': 'false',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_vehicles = urllib.parse.urlencode(vehicles).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_vehicles = urllib.request.urlopen(url, encode_vehicles)\n",
    "query_vehicles = response_vehicles.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"shapefiles/vehicles/vehicles18.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_vehicles)\n",
    "    \n",
    "# We check the results\n",
    "    # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8. Check Section 3\n",
    "with open('shapefiles/vehicles/vehicles18.json','r') as f:\n",
    "    data = json.loads(f.read())\n",
    "vehicles_df = pd.json_normalize(data, record_path = [\"features\"])\n",
    "len(vehicles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
