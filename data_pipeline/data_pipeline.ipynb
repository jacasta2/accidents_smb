{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook was last run on Jan 24, 2023. Recall that the initial ETL process pulled 2015-Aug 2022 data from the GIS web\n",
    "# service to populate a local Postgres database. Initially, I \"manually\" ran the notebook to update the database with Sep, Oct\n",
    "# and Nov 2022 data, running it separately for each month after updating the 'where' clause from the layers Siniestro,\n",
    "# Con Herido and Con Muerto by manually entering the corresponding year and month, e.g.,\n",
    "# \n",
    "# where_clause = \"ANO_OCURRENCIA_ACC = 2022 AND MES_OCURRENCIA_ACC = 'SEPTIEMBRE'\" \n",
    "#\n",
    "# I then made use of the code from the cell below and updated the 'where' clause from the mentioned layers to update the\n",
    "# database with Dec 2022 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When updating the database, the idea is to place ourselves in the current year and month (year yt and\n",
    "# month mt = 1, 2, ..., 12) to update the database with data from year yt and month mt-1. The dictionary below reflects such a\n",
    "# mapping, while the code that follows controls the case where the current month is Jan (mt = 1), which indicates we need to\n",
    "# update the database with data from month Dec (mt = 12) and year yt-1.\n",
    "\n",
    "# Given the time it takes for the Secretary of Mobility of Bogotá to update the GIS web service, we suggest to run this\n",
    "# notebook halfway through the month\n",
    "\n",
    "month_es = {\n",
    "    \"01\":\"DICIEMBRE\",\n",
    "    \"02\":\"ENERO\",\n",
    "    \"03\":\"FEBRERO\",\n",
    "    \"04\":\"MARZO\",\n",
    "    \"05\":\"ABRIL\",\n",
    "    \"06\":\"MAYO\",\n",
    "    \"07\":\"JUNIO\",\n",
    "    \"08\":\"JULIO\",\n",
    "    \"09\":\"AGOSTO\",\n",
    "    \"10\":\"SEPTIEMBRE\",\n",
    "    \"11\":\"OCTUBRE\",\n",
    "    \"12\":\"NOVIEMBRE\",\n",
    "}\n",
    "\n",
    "today = datetime.date.today()\n",
    "year_today = today.year\n",
    "month_today = today.strftime(\"%m\")\n",
    "\n",
    "year_query = year_today\n",
    "month_query = month_es.get(month_today)\n",
    "\n",
    "if month_today == \"01\":\n",
    "    year_query = year_query - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FORMULARIO</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>CIV</th>\n",
       "      <th>PK_CALZADA</th>\n",
       "      <th>CLASE_ACC</th>\n",
       "      <th>GRAVEDAD</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>ANO_OCURRENCIA_ACC</th>\n",
       "      <th>MES_OCURRENCIA_ACC</th>\n",
       "      <th>MES_NRO_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_NRO_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_MES_OCURRENCIA_ACC</th>\n",
       "      <th>HORA_OCURRENCIA_ACC</th>\n",
       "      <th>FECHA_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>453101</td>\n",
       "      <td>A001519131</td>\n",
       "      <td>CIUDAD BOLIVAR</td>\n",
       "      <td>19007302</td>\n",
       "      <td>0</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>CON HERIDOS</td>\n",
       "      <td>-74.138204</td>\n",
       "      <td>4.557293</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>LUNES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453102</td>\n",
       "      <td>A001516348</td>\n",
       "      <td>ANTONIO NARINO</td>\n",
       "      <td>15000376</td>\n",
       "      <td>0</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>CON HERIDOS</td>\n",
       "      <td>-74.115338</td>\n",
       "      <td>4.592395</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>LUNES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>453104</td>\n",
       "      <td>A001519104</td>\n",
       "      <td>BOSA</td>\n",
       "      <td>7006556</td>\n",
       "      <td>0</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>CON HERIDOS</td>\n",
       "      <td>-74.189906</td>\n",
       "      <td>4.603582</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>LUNES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453107</td>\n",
       "      <td>A001518989</td>\n",
       "      <td>SUBA</td>\n",
       "      <td>50007697</td>\n",
       "      <td>0</td>\n",
       "      <td>ATROPELLO</td>\n",
       "      <td>CON HERIDOS</td>\n",
       "      <td>-74.096169</td>\n",
       "      <td>4.746282</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>MARTES</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453108</td>\n",
       "      <td>A001518963</td>\n",
       "      <td>CHAPINERO</td>\n",
       "      <td>2001760</td>\n",
       "      <td>0</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>CON HERIDOS</td>\n",
       "      <td>-74.066455</td>\n",
       "      <td>4.638471</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>MARTES</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  FORMULARIO       LOCALIDAD       CIV  PK_CALZADA  CLASE_ACC  \\\n",
       "0    453101  A001519131  CIUDAD BOLIVAR  19007302           0     CHOQUE   \n",
       "1    453102  A001516348  ANTONIO NARINO  15000376           0     CHOQUE   \n",
       "2    453104  A001519104            BOSA   7006556           0     CHOQUE   \n",
       "3    453107  A001518989            SUBA  50007697           0  ATROPELLO   \n",
       "4    453108  A001518963       CHAPINERO   2001760           0     CHOQUE   \n",
       "\n",
       "      GRAVEDAD   LONGITUD   LATITUD  ANO_OCURRENCIA_ACC MES_OCURRENCIA_ACC  \\\n",
       "0  CON HERIDOS -74.138204  4.557293                2023              ENERO   \n",
       "1  CON HERIDOS -74.115338  4.592395                2023              ENERO   \n",
       "2  CON HERIDOS -74.189906  4.603582                2023              ENERO   \n",
       "3  CON HERIDOS -74.096169  4.746282                2023              ENERO   \n",
       "4  CON HERIDOS -74.066455  4.638471                2023              ENERO   \n",
       "\n",
       "   MES_NRO_OCURRENCIA_ACC DIA_OCURRENCIA_ACC  DIA_NRO_OCURRENCIA_ACC  \\\n",
       "0                       1              LUNES                       1   \n",
       "1                       1              LUNES                       1   \n",
       "2                       1              LUNES                       1   \n",
       "3                       1             MARTES                       2   \n",
       "4                       1             MARTES                       2   \n",
       "\n",
       "   DIA_MES_OCURRENCIA_ACC  HORA_OCURRENCIA_ACC   FECHA_ACC  \n",
       "0                       2                   11  2023-01-02  \n",
       "1                       2                   10  2023-01-02  \n",
       "2                       2                   23  2023-01-02  \n",
       "3                       3                   15  2023-01-03  \n",
       "4                       3                    0  2023-01-03  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "##### Accidents #####\n",
    "##################################################\n",
    "\n",
    "##### PULLING DATA FROM GIS WEB SERVICE\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/0/query?\"\n",
    "\n",
    "where_clause = \"ANO_OCURRENCIA_ACC = \" + str(year_query) + \" AND MES_OCURRENCIA_ACC = '\" + month_query + \"'\"\n",
    "accidents = {'where': where_clause,\n",
    "    'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CIV, PK_CALZADA, CLASE_ACC, GRAVEDAD, FECHA_HORA_ACC',\n",
    "    'returnGeometry': 'true',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_accidents = urllib.parse.urlencode(accidents).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_accidents = urllib.request.urlopen(url, encode_accidents)\n",
    "query_accidents = response_accidents.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"pipeline_accidents.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_accidents)\n",
    "# We load the JSON file into a DataFrame \n",
    "with open(\"pipeline_accidents.json\", \"r\") as f:\n",
    "    accidents_df = pd.json_normalize(json.loads(f.read()), \"features\")\n",
    "\n",
    "# We delete the JSON file\n",
    "    # https://linuxize.com/post/python-delete-files-and-directories/\n",
    "os.unlink(\"pipeline_accidents.json\")\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "column_dict = {} \n",
    "for i in range(len(accidents_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({accidents_df.columns[i]: accidents_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "accidents_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "##### DATA PREPARATION\n",
    "\n",
    "# All data preparation of this and the remaining tables is done based on the data preparation performed during the initial\n",
    "# ETL process (see the notebooks 3_data_preparation and 4_database_creation from the folder initial_etl)\n",
    "\n",
    "# Extract date info\n",
    "    # The unix time is UTC time, which is five hours ahead of Bogotá\n",
    "    # https://thispointer.com/subtract-hours-from-datetime-in-python/\n",
    "accidents_df[\"FECHA_HORA_ACC_r\"] = pd.to_datetime(accidents_df[\"FECHA_HORA_ACC\"], unit = \"ms\") - pd.DateOffset(hours = 5)\n",
    "\n",
    "# The following approach is more formal, but leaves the column with a final \"flag\" indicating the time difference\n",
    "# w.r.t. UTC\n",
    "#accidents_df[\"FECHA_HORA_ACC_r\"] = pd.to_datetime(accidents_df[\"FECHA_HORA_ACC\"], unit = \"ms\").dt.tz_localize(\"UTC\").\\\n",
    "#    dt.tz_convert(\"America/Bogota\")\n",
    "\n",
    "accidents_df[\"ANO_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.year\n",
    "\n",
    "# Install the Spanish locale before running the following code\n",
    "    # https://serverpilot.io/docs/how-to-install-locales/\n",
    "accidents_df[\"MES_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.month_name(locale = \"es_ES.UTF-8\")\n",
    "accidents_df[\"MES_NRO_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.month\n",
    "accidents_df[\"DIA_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.day_name(locale = \"es_ES.UTF-8\")\n",
    "\n",
    "# 1 is Monday, 2 is Tuesday and so on\n",
    "accidents_df[\"DIA_NRO_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.dayofweek + 1\n",
    "\n",
    "accidents_df[\"DIA_MES_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.day\n",
    "accidents_df[\"HORA_OCURRENCIA_ACC\"] = accidents_df[\"FECHA_HORA_ACC_r\"].dt.hour\n",
    "\n",
    "# Uppercase month and day of week to keep consistency with original format\n",
    "accidents_df[\"MES_OCURRENCIA_ACC\"] = accidents_df[\"MES_OCURRENCIA_ACC\"].str.upper()\n",
    "accidents_df[\"DIA_OCURRENCIA_ACC\"] = accidents_df[\"DIA_OCURRENCIA_ACC\"].str.upper()\n",
    "\n",
    "# Rename the longitude and latitude columns\n",
    "accidents_df.rename(columns = {\"geometry.x\": \"LONGITUDE\", \"geometry.y\": \"LATITUDE\"}, inplace = True)\n",
    "\n",
    "# CIV and PK_CALZADA NaN treatment: fill with 0s and then change their type to int\n",
    "accidents_df[\"CIV\"] = accidents_df[\"CIV\"].fillna(0)\n",
    "accidents_df[\"PK_CALZADA\"] = accidents_df[\"PK_CALZADA\"].fillna(0)\n",
    "accidents_df[\"CIV\"] = accidents_df[\"CIV\"].astype(int)\n",
    "accidents_df[\"PK_CALZADA\"] = accidents_df[\"PK_CALZADA\"].astype(int)\n",
    "\n",
    "# Make some final adjustments\n",
    "accidents_df[\"FECHA_ACC\"] = pd.to_datetime(accidents_df[\"FECHA_HORA_ACC_r\"], unit = \"ms\").dt.date\n",
    "accidents_df.drop({\"FECHA_HORA_ACC\", \"FECHA_HORA_ACC_r\"}, axis = 1, inplace = True)\n",
    "accidents_df.rename(columns = {\"LONGITUDE\": \"LONGITUD\", \"LATITUDE\": \"LATITUD\"}, inplace = True)\n",
    "accidents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FORMULARIO</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>CLASE_ACC</th>\n",
       "      <th>CONDICION</th>\n",
       "      <th>GENERO</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>ANO_OCURRENCIA_ACC</th>\n",
       "      <th>MES_OCURRENCIA_ACC</th>\n",
       "      <th>MES_NRO_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_NRO_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_MES_OCURRENCIA_ACC</th>\n",
       "      <th>HORA_OCURRENCIA_ACC</th>\n",
       "      <th>FECHA_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1425901</td>\n",
       "      <td>A001518356</td>\n",
       "      <td>SAN CRISTOBAL</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>MOTOCICLISTA</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-74.094279</td>\n",
       "      <td>4.567116</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>DOMINGO</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1425848</td>\n",
       "      <td>A001518554</td>\n",
       "      <td>BOSA</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>MOTOCICLISTA</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-74.208053</td>\n",
       "      <td>4.611807</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>DOMINGO</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429388</td>\n",
       "      <td>A001519079</td>\n",
       "      <td>SUBA</td>\n",
       "      <td>ATROPELLO</td>\n",
       "      <td>PEATON</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-74.084957</td>\n",
       "      <td>4.726734</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>DOMINGO</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1429387</td>\n",
       "      <td>A001519079</td>\n",
       "      <td>SUBA</td>\n",
       "      <td>ATROPELLO</td>\n",
       "      <td>PEATON</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-74.084957</td>\n",
       "      <td>4.726734</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>DOMINGO</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1425833</td>\n",
       "      <td>A001518544</td>\n",
       "      <td>SUBA</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>CONDUCTOR</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-74.094743</td>\n",
       "      <td>4.720117</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>DOMINGO</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  FORMULARIO      LOCALIDAD  CLASE_ACC     CONDICION     GENERO  \\\n",
       "0   1425901  A001518356  SAN CRISTOBAL     CHOQUE  MOTOCICLISTA  MASCULINO   \n",
       "1   1425848  A001518554           BOSA     CHOQUE  MOTOCICLISTA  MASCULINO   \n",
       "2   1429388  A001519079           SUBA  ATROPELLO        PEATON   FEMENINO   \n",
       "3   1429387  A001519079           SUBA  ATROPELLO        PEATON  MASCULINO   \n",
       "4   1425833  A001518544           SUBA     CHOQUE     CONDUCTOR  MASCULINO   \n",
       "\n",
       "   EDAD   LONGITUD   LATITUD  ANO_OCURRENCIA_ACC MES_OCURRENCIA_ACC  \\\n",
       "0  20.0 -74.094279  4.567116                2023              ENERO   \n",
       "1  23.0 -74.208053  4.611807                2023              ENERO   \n",
       "2  50.0 -74.084957  4.726734                2023              ENERO   \n",
       "3  43.0 -74.084957  4.726734                2023              ENERO   \n",
       "4  70.0 -74.094743  4.720117                2023              ENERO   \n",
       "\n",
       "   MES_NRO_OCURRENCIA_ACC DIA_OCURRENCIA_ACC  DIA_NRO_OCURRENCIA_ACC  \\\n",
       "0                       1            DOMINGO                       7   \n",
       "1                       1            DOMINGO                       7   \n",
       "2                       1            DOMINGO                       7   \n",
       "3                       1            DOMINGO                       7   \n",
       "4                       1            DOMINGO                       7   \n",
       "\n",
       "   DIA_MES_OCURRENCIA_ACC  HORA_OCURRENCIA_ACC   FECHA_ACC  \n",
       "0                       1                    8  2023-01-01  \n",
       "1                       1                   12  2023-01-01  \n",
       "2                       1                    2  2023-01-01  \n",
       "3                       1                    2  2023-01-01  \n",
       "4                       1                    7  2023-01-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "##### Injured people #####\n",
    "##################################################\n",
    "\n",
    "##### PULLING DATA FROM GIS WEB SERVICE\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/2/query?\"\n",
    "\n",
    "where_clause = \"ANO_OCURRENCIA_ACC = \" + str(year_query) + \" AND MES_OCURRENCIA_ACC = '\" + month_query + \"'\"\n",
    "injured_people = {'where': where_clause,\n",
    "    'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CLASE_ACC, CONDICION, GENERO, EDAD, FECHA_HORA_ACC',\n",
    "    'returnGeometry': 'true',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_injured_people = urllib.parse.urlencode(injured_people).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_injured_people = urllib.request.urlopen(url, encode_injured_people)\n",
    "query_injured_people = response_injured_people.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"pipeline_injured_people.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_injured_people)\n",
    "# We load the JSON file into a DataFrame \n",
    "with open(\"pipeline_injured_people.json\", \"r\") as f:\n",
    "    injured_people_df = pd.json_normalize(json.loads(f.read()), \"features\")\n",
    "\n",
    "# We delete the JSON file\n",
    "    # https://linuxize.com/post/python-delete-files-and-directories/\n",
    "os.unlink(\"pipeline_injured_people.json\")\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "column_dict = {} \n",
    "for i in range(len(injured_people_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({injured_people_df.columns[i]: injured_people_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "injured_people_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "##### DATA PREPARATION\n",
    "\n",
    "# Extract date info\n",
    "    # The unix time is UTC time, which is five hours ahead of Bogotá\n",
    "    # https://thispointer.com/subtract-hours-from-datetime-in-python/\n",
    "injured_people_df[\"FECHA_HORA_ACC_r\"] = pd.to_datetime(injured_people_df[\"FECHA_HORA_ACC\"], unit = \"ms\") - pd.DateOffset(hours = 5)\n",
    "\n",
    "# The following approach is more formal, but leaves the column with a final \"flag\" indicating the time difference\n",
    "# w.r.t. UTC\n",
    "#injured_people_df[\"FECHA_HORA_ACC_r\"] = pd.to_datetime(injured_people_df[\"FECHA_HORA_ACC\"], unit = \"ms\").dt.tz_localize(\"UTC\").\\\n",
    "#    dt.tz_convert(\"America/Bogota\")\n",
    "\n",
    "injured_people_df[\"ANO_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.year\n",
    "\n",
    "# Install the Spanish locale before running the following code\n",
    "    # https://serverpilot.io/docs/how-to-install-locales/\n",
    "injured_people_df[\"MES_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.month_name(locale = \"es_ES.UTF-8\")\n",
    "injured_people_df[\"MES_NRO_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.month\n",
    "injured_people_df[\"DIA_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.day_name(locale = \"es_ES.UTF-8\")\n",
    "\n",
    "# 1 is Monday, 2 is Tuesday and so on\n",
    "injured_people_df[\"DIA_NRO_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.dayofweek + 1\n",
    "\n",
    "injured_people_df[\"DIA_MES_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.day\n",
    "injured_people_df[\"HORA_OCURRENCIA_ACC\"] = injured_people_df[\"FECHA_HORA_ACC_r\"].dt.hour\n",
    "\n",
    "# Uppercase month and day of week to keep consistency with original format\n",
    "injured_people_df[\"MES_OCURRENCIA_ACC\"] = injured_people_df[\"MES_OCURRENCIA_ACC\"].str.upper()\n",
    "injured_people_df[\"DIA_OCURRENCIA_ACC\"] = injured_people_df[\"DIA_OCURRENCIA_ACC\"].str.upper()\n",
    "\n",
    "# Rename the longitude and latitude columns\n",
    "injured_people_df.rename(columns = {\"geometry.x\": \"LONGITUDE\", \"geometry.y\": \"LATITUDE\"}, inplace = True)\n",
    "\n",
    "# GENERO NaN treatment: fill with \"SIN INFORMACION\"\n",
    "injured_people_df[\"GENERO\"] = injured_people_df[\"GENERO\"].fillna(\"SIN INFORMACION\")\n",
    "\n",
    "# EDAD NaN treatment: since we don't have information on what a zero represents (is it a baby that hasn't turned one year yet or\n",
    "# a null value?), we leave this feature as it is\n",
    "\n",
    "# Make some final adjustments\n",
    "injured_people_df[\"FECHA_ACC\"] = pd.to_datetime(injured_people_df[\"FECHA_HORA_ACC_r\"], unit = \"ms\").dt.date\n",
    "injured_people_df.drop({\"FECHA_HORA_ACC\", \"FECHA_HORA_ACC_r\"}, axis = 1, inplace = True)\n",
    "injured_people_df.rename(columns = {\"LONGITUDE\": \"LONGITUD\", \"LATITUDE\": \"LATITUD\"}, inplace = True)\n",
    "injured_people_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FORMULARIO</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>CLASE_ACC</th>\n",
       "      <th>CONDICION</th>\n",
       "      <th>GENERO</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>MUERTE_POSTERIOR</th>\n",
       "      <th>FECHA_POSTERIOR_MUERTE</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>ANO_OCURRENCIA_ACC</th>\n",
       "      <th>MES_OCURRENCIA_ACC</th>\n",
       "      <th>MES_NRO_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_NRO_OCURRENCIA_ACC</th>\n",
       "      <th>DIA_MES_OCURRENCIA_ACC</th>\n",
       "      <th>HORA_OCURRENCIA_ACC</th>\n",
       "      <th>FECHA_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1414893</td>\n",
       "      <td>A001519811</td>\n",
       "      <td>KENNEDY</td>\n",
       "      <td>ATROPELLO</td>\n",
       "      <td>PEATON</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.146904</td>\n",
       "      <td>4.618255</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>DOMINGO</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>2023-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1417333</td>\n",
       "      <td>A001518441</td>\n",
       "      <td>BOSA</td>\n",
       "      <td>VOLCAMIENTO</td>\n",
       "      <td>MOTOCICLISTA</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>44.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.167467</td>\n",
       "      <td>4.595989</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>SÁBADO</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1415854</td>\n",
       "      <td>A001519199</td>\n",
       "      <td>BOSA</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>MOTOCICLISTA</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>44.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.189920</td>\n",
       "      <td>4.621967</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>MIÉRCOLES</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>2023-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1424492</td>\n",
       "      <td>A001519962</td>\n",
       "      <td>ANTONIO NARINO</td>\n",
       "      <td>CHOQUE</td>\n",
       "      <td>MOTOCICLISTA</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>25.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.102841</td>\n",
       "      <td>4.586277</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>JUEVES</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>2023-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1423628</td>\n",
       "      <td>A001518935</td>\n",
       "      <td>KENNEDY</td>\n",
       "      <td>ATROPELLO</td>\n",
       "      <td>PEATON</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>25.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.137951</td>\n",
       "      <td>4.627230</td>\n",
       "      <td>2023</td>\n",
       "      <td>ENERO</td>\n",
       "      <td>1</td>\n",
       "      <td>LUNES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  FORMULARIO       LOCALIDAD    CLASE_ACC     CONDICION     GENERO  \\\n",
       "0   1414893  A001519811         KENNEDY    ATROPELLO        PEATON   FEMENINO   \n",
       "1   1417333  A001518441            BOSA  VOLCAMIENTO  MOTOCICLISTA  MASCULINO   \n",
       "2   1415854  A001519199            BOSA       CHOQUE  MOTOCICLISTA  MASCULINO   \n",
       "3   1424492  A001519962  ANTONIO NARINO       CHOQUE  MOTOCICLISTA  MASCULINO   \n",
       "4   1423628  A001518935         KENNEDY    ATROPELLO        PEATON  MASCULINO   \n",
       "\n",
       "   EDAD MUERTE_POSTERIOR  FECHA_POSTERIOR_MUERTE   LONGITUD   LATITUD  \\\n",
       "0  23.0                N                     NaN -74.146904  4.618255   \n",
       "1  44.0                N                     NaN -74.167467  4.595989   \n",
       "2  44.0                N                     NaN -74.189920  4.621967   \n",
       "3  25.0                N                     NaN -74.102841  4.586277   \n",
       "4  25.0                N                     NaN -74.137951  4.627230   \n",
       "\n",
       "   ANO_OCURRENCIA_ACC MES_OCURRENCIA_ACC  MES_NRO_OCURRENCIA_ACC  \\\n",
       "0                2023              ENERO                       1   \n",
       "1                2023              ENERO                       1   \n",
       "2                2023              ENERO                       1   \n",
       "3                2023              ENERO                       1   \n",
       "4                2023              ENERO                       1   \n",
       "\n",
       "  DIA_OCURRENCIA_ACC  DIA_NRO_OCURRENCIA_ACC  DIA_MES_OCURRENCIA_ACC  \\\n",
       "0            DOMINGO                       7                      22   \n",
       "1             SÁBADO                       6                      21   \n",
       "2          MIÉRCOLES                       3                      18   \n",
       "3             JUEVES                       4                      26   \n",
       "4              LUNES                       1                       2   \n",
       "\n",
       "   HORA_OCURRENCIA_ACC   FECHA_ACC  \n",
       "0                   19  2023-01-22  \n",
       "1                   15  2023-01-21  \n",
       "2                   23  2023-01-18  \n",
       "3                   21  2023-01-26  \n",
       "4                    3  2023-01-02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "##### Killed people #####\n",
    "##################################################\n",
    "\n",
    "##### PULLING DATA FROM GIS WEB SERVICE\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/1/query?\"\n",
    "\n",
    "where_clause = \"ANO_OCURRENCIA_ACC = \" + str(year_query) + \" AND MES_OCURRENCIA_ACC = '\" + month_query + \"'\"\n",
    "killed_people = {'where': where_clause,\n",
    "    'outFields': 'OBJECTID, FORMULARIO, LOCALIDAD, CLASE_ACC, CONDICION, GENERO, EDAD, MUERTE_POSTERIOR, FECHA_POSTERIOR_MUERTE, FECHA_HORA_ACC',\n",
    "    'returnGeometry': 'true',      \n",
    "    'f': 'json',\n",
    "}\n",
    "encode_killed_people = urllib.parse.urlencode(killed_people).encode(\"utf-8\")\n",
    "\n",
    "# We create a request and read it using urllib\n",
    "response_killed_people = urllib.request.urlopen(url, encode_killed_people)\n",
    "query_killed_people = response_killed_people.read()\n",
    "\n",
    "# We write the JSON response to a file\n",
    "with open(\"pipeline_killed_people.json\", \"wb\") as json_file:\n",
    "    json_file.write(query_killed_people)\n",
    "# We load the JSON file into a DataFrame \n",
    "with open(\"pipeline_killed_people.json\", \"r\") as f:\n",
    "    killed_people_df = pd.json_normalize(json.loads(f.read()), \"features\")\n",
    "\n",
    "# We delete the JSON file\n",
    "    # https://linuxize.com/post/python-delete-files-and-directories/\n",
    "os.unlink(\"pipeline_killed_people.json\")\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "column_dict = {} \n",
    "for i in range(len(killed_people_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({killed_people_df.columns[i]: killed_people_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "killed_people_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "##### DATA PREPARATION\n",
    "\n",
    "# Extract date info\n",
    "    # The unix time is UTC time, which is five hours ahead of Bogotá\n",
    "    # https://thispointer.com/subtract-hours-from-datetime-in-python/\n",
    "killed_people_df[\"FECHA_HORA_ACC_r\"] = pd.to_datetime(killed_people_df[\"FECHA_HORA_ACC\"], unit = \"ms\") - pd.DateOffset(hours = 5)\n",
    "\n",
    "# The following approach is more formal, but leaves the column with a final \"flag\" indicating the time difference\n",
    "# w.r.t. UTC\n",
    "#killed_people_df[\"FECHA_HORA_ACC_r\"] = pd.to_datetime(killed_people_df[\"FECHA_HORA_ACC\"], unit = \"ms\").dt.tz_localize(\"UTC\").\\\n",
    "#    dt.tz_convert(\"America/Bogota\")\n",
    "\n",
    "killed_people_df[\"ANO_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.year\n",
    "\n",
    "# Install the Spanish locale before running the following code\n",
    "    # https://serverpilot.io/docs/how-to-install-locales/\n",
    "killed_people_df[\"MES_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.month_name(locale = \"es_ES.UTF-8\")\n",
    "killed_people_df[\"MES_NRO_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.month\n",
    "killed_people_df[\"DIA_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.day_name(locale = \"es_ES.UTF-8\")\n",
    "\n",
    "# 1 is Monday, 2 is Tuesday and so on\n",
    "killed_people_df[\"DIA_NRO_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.dayofweek + 1\n",
    "\n",
    "killed_people_df[\"DIA_MES_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.day\n",
    "killed_people_df[\"HORA_OCURRENCIA_ACC\"] = killed_people_df[\"FECHA_HORA_ACC_r\"].dt.hour\n",
    "\n",
    "# Uppercase month and day of week to keep consistency with original format\n",
    "killed_people_df[\"MES_OCURRENCIA_ACC\"] = killed_people_df[\"MES_OCURRENCIA_ACC\"].str.upper()\n",
    "killed_people_df[\"DIA_OCURRENCIA_ACC\"] = killed_people_df[\"DIA_OCURRENCIA_ACC\"].str.upper()\n",
    "\n",
    "# Rename the longitude and latitude columns\n",
    "killed_people_df.rename(columns = {\"geometry.x\": \"LONGITUDE\", \"geometry.y\": \"LATITUDE\"}, inplace = True)\n",
    "\n",
    "# GENERO NaN treatment: fill with \"SIN INFORMACION\"\n",
    "killed_people_df[\"GENERO\"] = killed_people_df[\"GENERO\"].fillna(\"SIN INFORMACION\")\n",
    "\n",
    "# MUERTE_POSTERIOR NaN treatment: fill with \"N\" (the person die in the accident, not after)\n",
    "killed_people_df[\"MUERTE_POSTERIOR\"] = killed_people_df[\"MUERTE_POSTERIOR\"].fillna(\"N\")\n",
    "\n",
    "# EDAD NaN treatment: since we don't have information on what a zero represents (is it a baby that hasn't turned one year yet or\n",
    "# a null value?), we leave this feature as it is\n",
    "\n",
    "# Make some final adjustments\n",
    "killed_people_df[\"FECHA_ACC\"] = pd.to_datetime(killed_people_df[\"FECHA_HORA_ACC_r\"], unit = \"ms\").dt.date\n",
    "killed_people_df.drop({\"FECHA_HORA_ACC\", \"FECHA_HORA_ACC_r\"}, axis = 1, inplace = True)\n",
    "killed_people_df.rename(columns = {\"LONGITUDE\": \"LONGITUD\", \"LATITUDE\": \"LATITUD\"}, inplace = True)\n",
    "killed_people_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Iter: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FORMULARIO</th>\n",
       "      <th>CODIGO_VEHICULO</th>\n",
       "      <th>CODIGO_CAUSA</th>\n",
       "      <th>NOMBRE</th>\n",
       "      <th>TIPO</th>\n",
       "      <th>TIPO_CAUSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381090</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122</td>\n",
       "      <td>NO UTILIZAR - GIRAR BRUSCAMENTE</td>\n",
       "      <td>CG</td>\n",
       "      <td>CONDUCTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381091</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157</td>\n",
       "      <td>OTRA</td>\n",
       "      <td>CG</td>\n",
       "      <td>CONDUCTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>375129</td>\n",
       "      <td>A001514310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143</td>\n",
       "      <td>PONER EN MARCHA UN VEHICULO SIN PRECAUCIONES</td>\n",
       "      <td>CG</td>\n",
       "      <td>CONDUCTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>377143</td>\n",
       "      <td>A001514317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "      <td>ADELANTAR INVADIENDO VIA</td>\n",
       "      <td>CG</td>\n",
       "      <td>CONDUCTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377144</td>\n",
       "      <td>A001514317</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122</td>\n",
       "      <td>NO UTILIZAR - GIRAR BRUSCAMENTE</td>\n",
       "      <td>CG</td>\n",
       "      <td>CONDUCTOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  FORMULARIO  CODIGO_VEHICULO CODIGO_CAUSA  \\\n",
       "0    381090  A001513685              2.0          122   \n",
       "1    381091  A001513685              2.0          157   \n",
       "2    375129  A001514310              1.0          143   \n",
       "3    377143  A001514317              1.0          104   \n",
       "4    377144  A001514317              2.0          122   \n",
       "\n",
       "                                         NOMBRE TIPO TIPO_CAUSA  \n",
       "0               NO UTILIZAR - GIRAR BRUSCAMENTE   CG  CONDUCTOR  \n",
       "1                                          OTRA   CG  CONDUCTOR  \n",
       "2  PONER EN MARCHA UN VEHICULO SIN PRECAUCIONES   CG  CONDUCTOR  \n",
       "3                      ADELANTAR INVADIENDO VIA   CG  CONDUCTOR  \n",
       "4               NO UTILIZAR - GIRAR BRUSCAMENTE   CG  CONDUCTOR  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "##### Causes #####\n",
    "##################################################\n",
    "\n",
    "##### PULLING DATA FROM GIS WEB SERVICE\n",
    "\n",
    "# Given the lack of date information in the remaining layers of the GIS web service (Causa, Actor Vial and Vehiculo) and the\n",
    "# impossibility of executing JOIN operations in the service, we must rely on the FORMULARIO field from accidents_df to\n",
    "# retrieve the information from these layers\n",
    "\n",
    "formulario_series = accidents_df[\"FORMULARIO\"].copy()\n",
    "\n",
    "# The 'where' clause only allows up to 1.000 values inside IN (), so we need to loop accordingly. We have to execute a query n\n",
    "# times, each time but the last one with 1.000 FORMULARIO values inside IN (). In the last iteration, the number of FORMULARIO\n",
    "# values will depend on the size of formulario_series  \n",
    "\n",
    "# The following code creates the indexes for each query iteration. It controls whether the quantity of FORMULARIO values is \n",
    "# greater than 999 so that we can properly create the indexes and loop accordingly when creating the JSON files\n",
    "indexes = []\n",
    "\n",
    "if len(formulario_series) >= 1000:\n",
    "    formulario_loop = int(len(formulario_series)/1000)\n",
    "    for i in range(formulario_loop):\n",
    "        indexes.append([i*1000, i*1000 + 1000])\n",
    "    indexes.append([(i + 1)*1000, len(formulario_series)])\n",
    "else:\n",
    "    formulario_loop = 0\n",
    "    indexes.append([0, len(formulario_series)])   \n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/5/query?\"\n",
    "\n",
    "file_name_init = \"pipeline_causes\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file for each query iteration\n",
    "for i in range(formulario_loop + 1):\n",
    "    \n",
    "    # We specify the query\n",
    "    where_clause = \"FORMULARIO IN (\"\n",
    "    \n",
    "    # We append the FORMULARIO values to the 'where' clause\n",
    "    formulario_series_loop = formulario_series[indexes[i][0]:indexes[i][1]].copy()\n",
    "    for formulario in formulario_series_loop:\n",
    "        where_clause += \"'\" + formulario + \"', \"\n",
    "    where_clause = where_clause[:len(where_clause)-2] + \")\" # After this loop, where_clause ends with \", \", so we replace this\n",
    "        # with \")\" \n",
    "    \n",
    "    causes = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, CODIGO_VEHICULO, CODIGO_CAUSA, NOMBRE, TIPO, TIPO_CAUSA',\n",
    "        'returnGeometry': 'false',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_causes = urllib.parse.urlencode(causes).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_causes = urllib.request.urlopen(url, encode_causes)\n",
    "    query_causes = response_causes.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(i + 1) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_causes)\n",
    "    \n",
    "    print(\"Iter: \" + str(i)) # Keep track of the process (we know how many files we're creating)\n",
    "\n",
    "df_list = [] # List to store DataFrames generated from JSON files\n",
    "\n",
    "# Retrieve list of JSON files\n",
    "json_pattern = os.path.join(\"*.json\")\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "for file in file_list:\n",
    "    # Read a JSON file\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    # Load the JSON file into a DataFrame and store the DataFrame in a list of DataFrames\n",
    "        # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8. Check Section 3\n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "\n",
    "# We delete the JSON files\n",
    "    # https://linuxize.com/post/python-delete-files-and-directories/\n",
    "files = glob.glob(\"*.json\")\n",
    "for f in files:\n",
    "    os.unlink(f)\n",
    "\n",
    "# Concatenate all DataFrames from the list into a single DataFrame\n",
    "causes_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {} # Dictionary to store old and new column names for the concatenated DataFrame\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "for i in range(len(causes_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({causes_df.columns[i]: causes_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "causes_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "# In case we had worked with several JSON files, there could be repeated indexes after concatenating the DataFrames. We take\n",
    "# care of this by resetting the index and dropping the generated index column\n",
    "causes_df.reset_index(inplace = True)\n",
    "causes_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "##### DATA PREPARATION\n",
    "\n",
    "# Fill potential NaN values in TIPO and TIPO_CAUSA\n",
    "causes_df.fillna(\"SIN ESTABLECER\", inplace = True)\n",
    "\n",
    "# Do some cleaning in rows with values \"OTRAS\"\n",
    "causes_df[\"NOMBRE\"] = np.where(causes_df[\"NOMBRE\"] == \"OTRAS\", \"OTRA\", causes_df[\"NOMBRE\"])\n",
    "causes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Iter: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FORMULARIO</th>\n",
       "      <th>CODIGO_VICTIMA</th>\n",
       "      <th>CODIGO_VEHICULO</th>\n",
       "      <th>CONDICION</th>\n",
       "      <th>GENERO</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>MUERTE_POSTERIOR</th>\n",
       "      <th>FECHA_POSTERIOR_MUERTE</th>\n",
       "      <th>ESTADO_FINAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430268</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PASAJERO</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>41.0</td>\n",
       "      <td>HERIDO</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERIDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1430269</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PASAJERO</td>\n",
       "      <td>MASCULINO</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HERIDO</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERIDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1430270</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PASAJERO</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>46.0</td>\n",
       "      <td>HERIDO</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERIDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1430271</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PASAJERO</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>25.0</td>\n",
       "      <td>HERIDO</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERIDO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1430272</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>PASAJERO</td>\n",
       "      <td>FEMENINO</td>\n",
       "      <td>40.0</td>\n",
       "      <td>HERIDO</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HERIDO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  FORMULARIO  CODIGO_VICTIMA  CODIGO_VEHICULO CONDICION     GENERO  \\\n",
       "0   1430268  A001513685             6.0                1  PASAJERO  MASCULINO   \n",
       "1   1430269  A001513685             5.0                1  PASAJERO  MASCULINO   \n",
       "2   1430270  A001513685             4.0                1  PASAJERO   FEMENINO   \n",
       "3   1430271  A001513685             3.0                1  PASAJERO   FEMENINO   \n",
       "4   1430272  A001513685             2.0                1  PASAJERO   FEMENINO   \n",
       "\n",
       "   EDAD  ESTADO MUERTE_POSTERIOR FECHA_POSTERIOR_MUERTE ESTADO_FINAL  \n",
       "0  41.0  HERIDO                N                    NaN       HERIDO  \n",
       "1  20.0  HERIDO                N                    NaN       HERIDO  \n",
       "2  46.0  HERIDO                N                    NaN       HERIDO  \n",
       "3  25.0  HERIDO                N                    NaN       HERIDO  \n",
       "4  40.0  HERIDO                N                    NaN       HERIDO  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "##### Actors #####\n",
    "##################################################\n",
    "\n",
    "# PULLING DATA FROM GIS WEB SERVICE\n",
    "\n",
    "formulario_series = accidents_df[\"FORMULARIO\"].copy()\n",
    "indexes = []\n",
    "\n",
    "if len(formulario_series) >= 1000:\n",
    "    formulario_loop = int(len(formulario_series)/1000)\n",
    "    for i in range(formulario_loop):\n",
    "        indexes.append([i*1000, i*1000 + 1000])\n",
    "    indexes.append([(i + 1)*1000, len(formulario_series)])\n",
    "else:\n",
    "    formulario_loop = 0\n",
    "    indexes.append([0, len(formulario_series)])   \n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/6/query?\"\n",
    "\n",
    "file_name_init = \"pipeline_actors\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file for each query iteration\n",
    "for i in range(formulario_loop + 1):\n",
    "    \n",
    "    # We specify the query\n",
    "    where_clause = \"FORMULARIO IN (\"\n",
    "    \n",
    "    # We append the FORMULARIO values to the 'where' clause\n",
    "    formulario_series_loop = formulario_series[indexes[i][0]:indexes[i][1]].copy()\n",
    "    for formulario in formulario_series_loop:\n",
    "        where_clause += \"'\" + formulario + \"', \"\n",
    "    where_clause = where_clause[:len(where_clause)-2] + \")\" # After this loop, where_clause ends with \", \", so we replace this\n",
    "        # with \")\" \n",
    "    \n",
    "    actors = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, CODIGO_VICTIMA, CODIGO_VEHICULO, CONDICION, GENERO, EDAD, ESTADO, MUERTE_POSTERIOR, FECHA_POSTERIOR_MUERTE',\n",
    "        'returnGeometry': 'false',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_actors = urllib.parse.urlencode(actors).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_actors = urllib.request.urlopen(url, encode_actors)\n",
    "    query_actors = response_actors.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(i + 1) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_actors)\n",
    "    \n",
    "    print(\"Iter: \" + str(i)) # Keep track of the process (we know how many files we're creating)\n",
    "\n",
    "df_list = [] # List to store DataFrames generated from JSON files\n",
    "\n",
    "# Retrieve list of JSON files\n",
    "json_pattern = os.path.join(\"*.json\")\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "for file in file_list:\n",
    "    # Read a JSON file\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    # Load the JSON file into a DataFrame and store the DataFrame in a list of DataFrames\n",
    "        # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8. Check Section 3\n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "\n",
    "# We delete the JSON files\n",
    "    # https://linuxize.com/post/python-delete-files-and-directories/\n",
    "files = glob.glob(\"*.json\")\n",
    "for f in files:\n",
    "    os.unlink(f)\n",
    "\n",
    "# Concatenate all DataFrames from the list into a single DataFrame\n",
    "actors_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {} # Dictionary to store old and new column names for the concatenated DataFrame\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "for i in range(len(actors_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({actors_df.columns[i]: actors_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "actors_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "# In case we had worked with several JSON files, there could be repeated indexes after concatenating the DataFrames. We take\n",
    "# care of this by resetting the index and dropping the generated index column\n",
    "actors_df.reset_index(inplace = True)\n",
    "actors_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "##### DATA PREPARATION\n",
    "\n",
    "# GENERO NaN treatment: fill with \"SIN INFORMACION\"\n",
    "actors_df[\"GENERO\"] = actors_df[\"GENERO\"].fillna(\"SIN INFORMACION\")\n",
    "\n",
    "# EDAD NaN treatment: since we don't have information on what a zero represents (is it a baby that hasn't turned one year yet or\n",
    "# a null value?), we leave this feature as it is\n",
    "\n",
    "# CODIGO_VEHICULO and CONDICION NaN treatment: PASAJERO, PEATON and null values in CONDICION are associated with null values in\n",
    "# CODIGO_VEHICULO. We fill null values in CONDICION with \"SIN INFORMACION\" and null values in CODIGO_VEHICULO with 0s and then\n",
    "# change their type to int\n",
    "actors_df[\"CONDICION\"] = actors_df[\"CONDICION\"].fillna(\"SIN INFORMACION\")\n",
    "actors_df[\"CODIGO_VEHICULO\"] = actors_df[\"CODIGO_VEHICULO\"].fillna(0)\n",
    "actors_df[\"CODIGO_VEHICULO\"] = actors_df[\"CODIGO_VEHICULO\"].astype(int) \n",
    "\n",
    "# ESTADO NaN treatment: fill with \"ILESO\"\n",
    "actors_df[\"ESTADO\"] = actors_df[\"ESTADO\"].fillna(\"ILESO\")\n",
    "\n",
    "# Based on the initial ETL process, we engineer a new feature called ESTADO_FINAL\n",
    "actors_df[\"ESTADO_FINAL\"] = np.where((actors_df[\"ESTADO\"] == \"MUERTO\") | (actors_df[\"MUERTE_POSTERIOR\"] == \"S\"), \"MUERTO\", \\\n",
    "    actors_df[\"ESTADO\"])\n",
    "actors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Iter: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>FORMULARIO</th>\n",
       "      <th>CODIGO_VEHICULO</th>\n",
       "      <th>CLASE</th>\n",
       "      <th>SERVICIO</th>\n",
       "      <th>MODALIDAD</th>\n",
       "      <th>ENFUGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14284207</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>1</td>\n",
       "      <td>BUS</td>\n",
       "      <td>PUBLICO</td>\n",
       "      <td>PASAJEROS - MASIVO</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14284208</td>\n",
       "      <td>A001513685</td>\n",
       "      <td>2</td>\n",
       "      <td>AUTOMOVIL</td>\n",
       "      <td>SIN INFORMACION</td>\n",
       "      <td>SIN INFORMACION</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14283609</td>\n",
       "      <td>A001514310</td>\n",
       "      <td>1</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>SIN INFORMACION</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14283859</td>\n",
       "      <td>A001514317</td>\n",
       "      <td>1</td>\n",
       "      <td>MOTOCICLETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>SIN INFORMACION</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14283860</td>\n",
       "      <td>A001514317</td>\n",
       "      <td>2</td>\n",
       "      <td>CAMIONETA</td>\n",
       "      <td>PARTICULAR</td>\n",
       "      <td>SIN INFORMACION</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  FORMULARIO  CODIGO_VEHICULO        CLASE         SERVICIO  \\\n",
       "0  14284207  A001513685                1          BUS          PUBLICO   \n",
       "1  14284208  A001513685                2    AUTOMOVIL  SIN INFORMACION   \n",
       "2  14283609  A001514310                1    CAMIONETA       PARTICULAR   \n",
       "3  14283859  A001514317                1  MOTOCICLETA       PARTICULAR   \n",
       "4  14283860  A001514317                2    CAMIONETA       PARTICULAR   \n",
       "\n",
       "            MODALIDAD ENFUGA  \n",
       "0  PASAJEROS - MASIVO      N  \n",
       "1     SIN INFORMACION      S  \n",
       "2     SIN INFORMACION      N  \n",
       "3     SIN INFORMACION      N  \n",
       "4     SIN INFORMACION      N  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "##### Vehicles #####\n",
    "##################################################\n",
    "\n",
    "# PULLING DATA FROM GIS WEB SERVICE\n",
    "\n",
    "formulario_series = accidents_df[\"FORMULARIO\"].copy()\n",
    "indexes = []\n",
    "\n",
    "if len(formulario_series) >= 1000:\n",
    "    formulario_loop = int(len(formulario_series)/1000)\n",
    "    for i in range(formulario_loop):\n",
    "        indexes.append([i*1000, i*1000 + 1000])\n",
    "    indexes.append([(i + 1)*1000, len(formulario_series)])\n",
    "else:\n",
    "    formulario_loop = 0\n",
    "    indexes.append([0, len(formulario_series)])\n",
    "\n",
    "# We specify the URL\n",
    "url = \"https://sig.simur.gov.co/arcgis/rest/services/Accidentalidad/WSAcidentalidad_Publico/FeatureServer/4/query?\"\n",
    "\n",
    "file_name_init = \"pipeline_vehicles\"\n",
    "file_name_end = \".json\"\n",
    "\n",
    "# We create a JSON file for each query iteration\n",
    "for i in range(formulario_loop + 1):\n",
    "    \n",
    "    # We specify the query\n",
    "    where_clause = \"FORMULARIO IN (\"\n",
    "    \n",
    "    # We append the FORMULARIO values to the 'where' clause\n",
    "    formulario_series_loop = formulario_series[indexes[i][0]:indexes[i][1]].copy()\n",
    "    for formulario in formulario_series_loop:\n",
    "        where_clause += \"'\" + formulario + \"', \"\n",
    "    where_clause = where_clause[:len(where_clause)-2] + \")\" # After this loop, where_clause ends with \", \", so we replace this\n",
    "        # with \")\" \n",
    "    \n",
    "    vehicles = {'where': where_clause,\n",
    "        'outFields': 'OBJECTID, FORMULARIO, CODIGO_VEHICULO, CLASE, SERVICIO, MODALIDAD, ENFUGA',\n",
    "        'returnGeometry': 'false',      \n",
    "        'f': 'json',\n",
    "    }\n",
    "    encode_vehicles = urllib.parse.urlencode(vehicles).encode(\"utf-8\")\n",
    "    \n",
    "    # We create a request and read it using urllib\n",
    "    response_vehicles = urllib.request.urlopen(url, encode_vehicles)\n",
    "    query_vehicles = response_vehicles.read()\n",
    "    \n",
    "    # We write the JSON response to a file\n",
    "    file_name = file_name_init + str(i + 1) + file_name_end\n",
    "    with open(file_name, \"wb\") as json_file:\n",
    "        json_file.write(query_vehicles)\n",
    "    \n",
    "    print(\"Iter: \" + str(i)) # Keep track of the process (we know how many files we're creating)\n",
    "\n",
    "df_list = [] # List to store DataFrames generated from JSON files\n",
    "\n",
    "# Retrieve list of JSON files\n",
    "json_pattern = os.path.join(\"*.json\")\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "for file in file_list:\n",
    "    # Read a JSON file\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    # Load the JSON file into a DataFrame and store the DataFrame in a list of DataFrames\n",
    "        # https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8. Check Section 3\n",
    "    df_list.append(pd.json_normalize(data, \"features\"))\n",
    "\n",
    "# We delete the JSON files\n",
    "    # https://linuxize.com/post/python-delete-files-and-directories/\n",
    "files = glob.glob(\"*.json\")\n",
    "for f in files:\n",
    "    os.unlink(f)\n",
    "\n",
    "# Concatenate all DataFrames from the list into a single DataFrame\n",
    "vehicles_df = pd.concat(df_list, axis = 0)\n",
    "\n",
    "column_dict = {} # Dictionary to store old and new column names for the concatenated DataFrame\n",
    "\n",
    "# We rename the columns by removing \"attributes.\" from their names\n",
    "for i in range(len(vehicles_df.columns)):\n",
    "    # Map the old column names with the new ones (without \"attributes.\") and store the mapping in a dictionary\n",
    "    column_dict.update({vehicles_df.columns[i]: vehicles_df.columns[i].replace(\"attributes.\", \"\")})\n",
    "\n",
    "# We rename the columns using the dictionary\n",
    "vehicles_df.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "# In case we had worked with several JSON files, there could be repeated indexes after concatenating the DataFrames. We take\n",
    "# care of this by resetting the index and dropping the generated index column\n",
    "vehicles_df.reset_index(inplace = True)\n",
    "vehicles_df.drop(\"index\", axis = 1, inplace = True)\n",
    "\n",
    "##### DATA PREPARATION\n",
    "\n",
    "# CODIGO_VEHICULO NaN treatment: fill with 1s and then change its type to int\n",
    "vehicles_df[\"CODIGO_VEHICULO\"] = vehicles_df[\"CODIGO_VEHICULO\"].fillna(1)\n",
    "vehicles_df[\"CODIGO_VEHICULO\"] = vehicles_df[\"CODIGO_VEHICULO\"].astype(int)\n",
    "\n",
    "# CLASE NaN treatment: fill with \"SIN INFORMACION\"\n",
    "vehicles_df[\"CLASE\"] = vehicles_df[\"CLASE\"].fillna(\"SIN INFORMACION\")\n",
    "\n",
    "# SERVICIO NaN treatment: fill with \"SIN INFORMACION\"\n",
    "# Do some cleaning in rows with values \" SIN INFORMACION\"\n",
    "vehicles_df[\"SERVICIO\"] = vehicles_df[\"SERVICIO\"].fillna(\"SIN INFORMACION\")\n",
    "vehicles_df[\"SERVICIO\"] = np.where(vehicles_df[\"SERVICIO\"] == \" SIN INFORMACION\", \"SIN INFORMACION\", vehicles_df[\"SERVICIO\"])\n",
    "\n",
    "# MODALIDAD NaN treatment: fill with \"SIN INFORMACION\".\n",
    "# While this could be done in a single step, we first checked with SERVICIO PUBLICO since the understanding was that MODALIDAD\n",
    "# was a feature that only applied to SERVICIO PUBLICO vehicles\n",
    "vehicles_df[\"MODALIDAD\"] = np.where((vehicles_df[\"SERVICIO\"] == \"PUBLICO\") & (vehicles_df[\"MODALIDAD\"].isna()), \\\n",
    "    \"SIN INFORMACION\", vehicles_df[\"MODALIDAD\"])\n",
    "vehicles_df[\"MODALIDAD\"] = np.where((vehicles_df[\"SERVICIO\"] != \"PUBLICO\") & (vehicles_df[\"MODALIDAD\"].isna()), \\\n",
    "    \"SIN INFORMACION\", vehicles_df[\"MODALIDAD\"])\n",
    "\n",
    "# Based on the initial ETL process, the ENFUGA NaN values are not treated since the info is rather confusing\n",
    "vehicles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the DataFrame is inserted\n",
      "the DataFrame is inserted\n",
      "the DataFrame is inserted\n",
      "the DataFrame is inserted\n",
      "the DataFrame is inserted\n",
      "the DataFrame is inserted\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "##### Update database #####\n",
    "##################################################\n",
    "\n",
    "# https://www.geeksforgeeks.org/how-to-insert-a-pandas-dataframe-to-an-existing-postgresql-table/\n",
    "def execute_values(conn, df, table):\n",
    "    \"\"\"\n",
    "    This function inserts a DataFrame into a given table from a given database.\n",
    "\n",
    "    Args:\n",
    "        conn: database connection.\n",
    "        df: DataFrame to be inserted.\n",
    "        table: table where the df is inserted. \n",
    "\n",
    "    Returns:\n",
    "        The table is updated with info from df.\n",
    "    \"\"\"\n",
    "\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the DataFrame is inserted\")\n",
    "    cursor.close()\n",
    "\n",
    "# We connect to the database accidents_smb\n",
    "db_conn = psycopg2.connect(\n",
    "   database = \"accidents_smb\", user = \"dev\", password = \"dev\", host = \"127.0.0.1\", port = \"5432\"\n",
    ")\n",
    "\n",
    "# We update the tables from accidents_smb with the info pulled from the GIS web service and further processed to keep\n",
    "# consistency with the structure defined in the initial ETL process\n",
    "execute_values(db_conn, accidents_df, \"siniestros\")\n",
    "execute_values(db_conn, injured_people_df, \"conheridos\")\n",
    "execute_values(db_conn, killed_people_df, \"confallecidos\")\n",
    "execute_values(db_conn, causes_df, \"causas\")\n",
    "execute_values(db_conn, actors_df, \"actores\")\n",
    "execute_values(db_conn, vehicles_df, \"vehiculos\")\n",
    "\n",
    "# We close the connection to accidents_smb\n",
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "14a8ab31f43739f8c61e31f0a764b4b9450b359fd4dd373e840d3db42f338d08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
